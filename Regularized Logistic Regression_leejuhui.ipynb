{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Dil34lm2V1T6"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "import io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB_0dFbHdrBg"
      },
      "source": [
        "# generating training dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "CHqtsBP8du2s",
        "outputId": "70d46822-5582-4647-87b2-4ff73da1172c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5aac8ceb-cd33-48ed-a23a-8431bc75466b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5aac8ceb-cd33-48ed-a23a-8431bc75466b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Train_Data.txt to Train_Data (1).txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-874026b3-d472-4658-b56d-64f695ee9b0c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-874026b3-d472-4658-b56d-64f695ee9b0c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Test_Data.txt to Test_Data (1).txt\n"
          ]
        }
      ],
      "source": [
        "# upload file with dictionary format, with key as name of uploaded file \n",
        "# and corresponding values as the contens of the file \n",
        "from google.colab import files\n",
        "uploaded_train = files.upload()\n",
        "uploaded_test = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlNQjWYg-y6F",
        "outputId": "9f24aec0-251f-44ad-a60f-695c9405cc00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          ID  x1  x2  x3  x4  x5  x6  x7  x8  x9  class\n",
            "0    1000025   5   1   1   1   2   1   3   1   1      2\n",
            "1    1002945   5   4   4   5   7  10   3   2   1      2\n",
            "2    1015425   3   1   1   1   2   2   3   1   1      2\n",
            "3    1016277   6   8   8   1   3   4   3   7   1      2\n",
            "4    1017023   4   1   1   3   2   1   3   1   1      2\n",
            "..       ...  ..  ..  ..  ..  ..  ..  ..  ..  ..    ...\n",
            "594  1315506   4   8   6   3   4  10   7   1   1      4\n",
            "595  1320141   5   1   1   1   2   1   2   1   1      2\n",
            "596  1325309   4   1   2   1   2   1   2   1   1      2\n",
            "597  1333063   5   1   3   1   2   1   3   1   1      2\n",
            "598  1333495   3   1   1   1   2   1   2   1   1      2\n",
            "\n",
            "[599 rows x 11 columns]\n",
            "         ID  x1  x2  x3  x4  x5 x6  x7  x8  x9  class\n",
            "0   1334659   5   2   4   1   1  1   1   1   1      2\n",
            "1   1336798   3   1   1   1   2  1   2   1   1      2\n",
            "2   1344449   1   1   1   1   1  1   2   1   1      2\n",
            "3   1350568   4   1   1   1   2  1   2   1   1      2\n",
            "4   1352663   5   4   6   8   4  1   8  10   1      4\n",
            "..      ...  ..  ..  ..  ..  .. ..  ..  ..  ..    ...\n",
            "95   776715   3   1   1   1   3  2   1   1   1      2\n",
            "96   841769   2   1   1   1   2  1   1   1   1      2\n",
            "97   888820   5  10  10   3   7  3   8  10   2      4\n",
            "98   897471   4   8   6   4   3  4  10   6   1      4\n",
            "99   897471   4   8   8   5   4  5  10   4   1      4\n",
            "\n",
            "[100 rows x 11 columns]\n"
          ]
        }
      ],
      "source": [
        "# use panda and io pachage to load txt. \n",
        "df_train = pd.read_csv(io.StringIO(uploaded_train['Train_Data.txt'].decode(\"utf-8\")), \n",
        "                       sep=',', names=['ID', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'class'], header=None)\n",
        "print(df_train)\n",
        "\n",
        "df_test = pd.read_csv(io.StringIO(uploaded_test['Test_Data.txt'].decode(\"utf-8\")), \n",
        "                       sep=',', names=['ID', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'class'], header=None)\n",
        "print(df_test)\n",
        "#replace missing value ? with 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXYIBh9jw9Hq"
      },
      "source": [
        "## Feature Selection or Manipulation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsHFLJ9oulM2",
        "outputId": "ac2b03f2-9d70-4012-fddf-d1b227cf25d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([599, 2])\n",
            "torch.Size([599, 1])\n"
          ]
        }
      ],
      "source": [
        "X = df_train[['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9']].replace({'?':0})\n",
        "# print(X['x6'][0:10])\n",
        "\n",
        "y = df_train['class'].replace({2:0, 4:1})\n",
        "# class 2 for benign, 4 for malignant -> 0 for bengn, 1 for malignant\n",
        "\n",
        "x_train = torch.Tensor(np.array([X['x1'], X['x7']]).astype(np.uint8)).t()  # str to unit, [3, 500] ->  [500, 3]\n",
        "print(x_train.shape)\n",
        "\n",
        "# class 2 for benign, 4 for malignant -> 0 for bengn, 1 for malignant\n",
        "y_train = torch.Tensor(y).unsqueeze(1) # [500] -> [500, 1]\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZbQkpxkhH6G"
      },
      "source": [
        "# Define model class\n",
        "z = w1*x1 + w2*x2 + w3*x3 ....  + w6*x6 + b  -> <br>\n",
        "y = a = sigma(z) -> <br>\n",
        "L(y_hat = a, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWDgg8yEhFMk",
        "outputId": "f6298afc-992b-4ce6-d115-7dda87fb42d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([599, 2])\n",
            "[Parameter containing:\n",
            "tensor([[ 0.3643, -0.3121]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.1371], requires_grad=True)]\n"
          ]
        }
      ],
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(input_size, output_size)\n",
        "\n",
        "  def forward(self, x): \n",
        "    pred = torch.sigmoid(self.linear(x))\n",
        "    return pred   #probability (not direct value)\n",
        "\n",
        "  def predict(self, x):\n",
        "    pred = self.forward(x)\n",
        "    if pred >= 0.5:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "print(x_train.shape)\n",
        "\n",
        "# instantiate model class\n",
        "torch.manual_seed(1)\n",
        "model = LogisticRegression(x_train.shape[1], 1) # [500, 2]\n",
        "print(list(model.parameters()))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08wLbfEljkE8"
      },
      "source": [
        "# function to get model parameters (w1, w2, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJX7kArljiPZ",
        "outputId": "81c1240b-39d5-43ba-8b76-9831b3ea4336"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3643, -0.3121]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "[w, b] = model.parameters() # Ws, bias\n",
        "print(w) \n",
        "w1, w2= w.view(x_train.shape[1])\n",
        "\n",
        "def get_params():\n",
        "  return (w1.item(), w2.item(), b[0].item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gkj4yqKlgcA"
      },
      "source": [
        "# training the model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkW2eQbklixb",
        "outputId": "8beaaad7-5a09-46e6-d768-bed727d7fc78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0 loss:  0.7587953805923462\n",
            "epoch:  1 loss:  0.7546693682670593\n",
            "epoch:  2 loss:  0.7475148439407349\n",
            "epoch:  3 loss:  0.7385463714599609\n",
            "epoch:  4 loss:  0.728583037853241\n",
            "epoch:  5 loss:  0.717842698097229\n",
            "epoch:  6 loss:  0.7061562538146973\n",
            "epoch:  7 loss:  0.6934270262718201\n",
            "epoch:  8 loss:  0.6799812316894531\n",
            "epoch:  9 loss:  0.6665436029434204\n",
            "epoch:  10 loss:  0.6538819670677185\n",
            "epoch:  11 loss:  0.6424261927604675\n",
            "epoch:  12 loss:  0.6321634650230408\n",
            "epoch:  13 loss:  0.6228452324867249\n",
            "epoch:  14 loss:  0.614288330078125\n",
            "epoch:  15 loss:  0.6065239906311035\n",
            "epoch:  16 loss:  0.5997124314308167\n",
            "epoch:  17 loss:  0.5939318537712097\n",
            "epoch:  18 loss:  0.5890355110168457\n",
            "epoch:  19 loss:  0.5846928954124451\n",
            "epoch:  20 loss:  0.5805608630180359\n",
            "epoch:  21 loss:  0.5764399766921997\n",
            "epoch:  22 loss:  0.5723041892051697\n",
            "epoch:  23 loss:  0.5682135820388794\n",
            "epoch:  24 loss:  0.5642006397247314\n",
            "epoch:  25 loss:  0.5602183938026428\n",
            "epoch:  26 loss:  0.556167483329773\n",
            "epoch:  27 loss:  0.551963210105896\n",
            "epoch:  28 loss:  0.547584593296051\n",
            "epoch:  29 loss:  0.5430780649185181\n",
            "epoch:  30 loss:  0.5385217070579529\n",
            "epoch:  31 loss:  0.5339798927307129\n",
            "epoch:  32 loss:  0.5294781923294067\n",
            "epoch:  33 loss:  0.5250100493431091\n",
            "epoch:  34 loss:  0.5205636620521545\n",
            "epoch:  35 loss:  0.5161463022232056\n",
            "epoch:  36 loss:  0.5117899179458618\n",
            "epoch:  37 loss:  0.5075370073318481\n",
            "epoch:  38 loss:  0.5034191608428955\n",
            "epoch:  39 loss:  0.4994463324546814\n",
            "epoch:  40 loss:  0.4956092834472656\n",
            "epoch:  41 loss:  0.49189236760139465\n",
            "epoch:  42 loss:  0.488285630941391\n",
            "epoch:  43 loss:  0.48478904366493225\n",
            "epoch:  44 loss:  0.4814080595970154\n",
            "epoch:  45 loss:  0.4781453311443329\n",
            "epoch:  46 loss:  0.47499513626098633\n",
            "epoch:  47 loss:  0.4719439446926117\n",
            "epoch:  48 loss:  0.468975692987442\n",
            "epoch:  49 loss:  0.46607786417007446\n",
            "epoch:  50 loss:  0.4632440507411957\n",
            "epoch:  51 loss:  0.4604729413986206\n",
            "epoch:  52 loss:  0.4577641189098358\n",
            "epoch:  53 loss:  0.4551151692867279\n",
            "epoch:  54 loss:  0.4525209367275238\n",
            "epoch:  55 loss:  0.44997525215148926\n",
            "epoch:  56 loss:  0.4474734365940094\n",
            "epoch:  57 loss:  0.4450135827064514\n",
            "epoch:  58 loss:  0.4425964951515198\n",
            "epoch:  59 loss:  0.4402239918708801\n",
            "epoch:  60 loss:  0.43789705634117126\n",
            "epoch:  61 loss:  0.43561556935310364\n",
            "epoch:  62 loss:  0.4333779811859131\n",
            "epoch:  63 loss:  0.431182861328125\n",
            "epoch:  64 loss:  0.4290294349193573\n",
            "epoch:  65 loss:  0.42691770195961\n",
            "epoch:  66 loss:  0.4248482286930084\n",
            "epoch:  67 loss:  0.4228215515613556\n",
            "epoch:  68 loss:  0.4208371043205261\n",
            "epoch:  69 loss:  0.4188939332962036\n",
            "epoch:  70 loss:  0.4169906675815582\n",
            "epoch:  71 loss:  0.4151257574558258\n",
            "epoch:  72 loss:  0.413298100233078\n",
            "epoch:  73 loss:  0.4115069508552551\n",
            "epoch:  74 loss:  0.4097515940666199\n",
            "epoch:  75 loss:  0.40803128480911255\n",
            "epoch:  76 loss:  0.4063449203968048\n",
            "epoch:  77 loss:  0.4046911299228668\n",
            "epoch:  78 loss:  0.40306878089904785\n",
            "epoch:  79 loss:  0.4014766812324524\n",
            "epoch:  80 loss:  0.39991381764411926\n",
            "epoch:  81 loss:  0.39837947487831116\n",
            "epoch:  82 loss:  0.3968730568885803\n",
            "epoch:  83 loss:  0.39539387822151184\n",
            "epoch:  84 loss:  0.3939410448074341\n",
            "epoch:  85 loss:  0.3925139605998993\n",
            "epoch:  86 loss:  0.39111173152923584\n",
            "epoch:  87 loss:  0.3897337317466736\n",
            "epoch:  88 loss:  0.38837939500808716\n",
            "epoch:  89 loss:  0.38704824447631836\n",
            "epoch:  90 loss:  0.38573986291885376\n",
            "epoch:  91 loss:  0.384453684091568\n",
            "epoch:  92 loss:  0.38318932056427\n",
            "epoch:  93 loss:  0.3819460868835449\n",
            "epoch:  94 loss:  0.3807237148284912\n",
            "epoch:  95 loss:  0.37952160835266113\n",
            "epoch:  96 loss:  0.3783392906188965\n",
            "epoch:  97 loss:  0.3771763741970062\n",
            "epoch:  98 loss:  0.3760325610637665\n",
            "epoch:  99 loss:  0.37490731477737427\n",
            "epoch:  100 loss:  0.3738003969192505\n",
            "epoch:  101 loss:  0.37271127104759216\n",
            "epoch:  102 loss:  0.3716394603252411\n",
            "epoch:  103 loss:  0.37058478593826294\n",
            "epoch:  104 loss:  0.36954671144485474\n",
            "epoch:  105 loss:  0.3685249090194702\n",
            "epoch:  106 loss:  0.3675190806388855\n",
            "epoch:  107 loss:  0.36652880907058716\n",
            "epoch:  108 loss:  0.3655538260936737\n",
            "epoch:  109 loss:  0.3645937442779541\n",
            "epoch:  110 loss:  0.36364826560020447\n",
            "epoch:  111 loss:  0.36271706223487854\n",
            "epoch:  112 loss:  0.36179986596107483\n",
            "epoch:  113 loss:  0.3608962893486023\n",
            "epoch:  114 loss:  0.36000609397888184\n",
            "epoch:  115 loss:  0.3591291010379791\n",
            "epoch:  116 loss:  0.35826489329338074\n",
            "epoch:  117 loss:  0.35741332173347473\n",
            "epoch:  118 loss:  0.35657405853271484\n",
            "epoch:  119 loss:  0.35574689507484436\n",
            "epoch:  120 loss:  0.3549315333366394\n",
            "epoch:  121 loss:  0.35412779450416565\n",
            "epoch:  122 loss:  0.353335440158844\n",
            "epoch:  123 loss:  0.3525542616844177\n",
            "epoch:  124 loss:  0.35178399085998535\n",
            "epoch:  125 loss:  0.35102447867393494\n",
            "epoch:  126 loss:  0.350275456905365\n",
            "epoch:  127 loss:  0.3495367765426636\n",
            "epoch:  128 loss:  0.3488081693649292\n",
            "epoch:  129 loss:  0.3480895757675171\n",
            "epoch:  130 loss:  0.347380667924881\n",
            "epoch:  131 loss:  0.34668129682540894\n",
            "epoch:  132 loss:  0.3459913730621338\n",
            "epoch:  133 loss:  0.34531062841415405\n",
            "epoch:  134 loss:  0.3446389138698578\n",
            "epoch:  135 loss:  0.34397611021995544\n",
            "epoch:  136 loss:  0.3433220684528351\n",
            "epoch:  137 loss:  0.34267643094062805\n",
            "epoch:  138 loss:  0.3420393168926239\n",
            "epoch:  139 loss:  0.34141039848327637\n",
            "epoch:  140 loss:  0.3407896161079407\n",
            "epoch:  141 loss:  0.3401767909526825\n",
            "epoch:  142 loss:  0.3395717442035675\n",
            "epoch:  143 loss:  0.33897438645362854\n",
            "epoch:  144 loss:  0.33838456869125366\n",
            "epoch:  145 loss:  0.33780214190483093\n",
            "epoch:  146 loss:  0.3372270464897156\n",
            "epoch:  147 loss:  0.3366590738296509\n",
            "epoch:  148 loss:  0.3360981345176697\n",
            "epoch:  149 loss:  0.3355441391468048\n",
            "epoch:  150 loss:  0.33499687910079956\n",
            "epoch:  151 loss:  0.33445629477500916\n",
            "epoch:  152 loss:  0.3339223265647888\n",
            "epoch:  153 loss:  0.3333948254585266\n",
            "epoch:  154 loss:  0.3328736424446106\n",
            "epoch:  155 loss:  0.3323586881160736\n",
            "epoch:  156 loss:  0.33184993267059326\n",
            "epoch:  157 loss:  0.33134710788726807\n",
            "epoch:  158 loss:  0.3308503329753876\n",
            "epoch:  159 loss:  0.3303593397140503\n",
            "epoch:  160 loss:  0.3298741579055786\n",
            "epoch:  161 loss:  0.3293945789337158\n",
            "epoch:  162 loss:  0.3289206027984619\n",
            "epoch:  163 loss:  0.32845208048820496\n",
            "epoch:  164 loss:  0.32798898220062256\n",
            "epoch:  165 loss:  0.3275311291217804\n",
            "epoch:  166 loss:  0.32707855105400085\n",
            "epoch:  167 loss:  0.3266310691833496\n",
            "epoch:  168 loss:  0.32618868350982666\n",
            "epoch:  169 loss:  0.32575124502182007\n",
            "epoch:  170 loss:  0.32531875371932983\n",
            "epoch:  171 loss:  0.3248910903930664\n",
            "epoch:  172 loss:  0.32446813583374023\n",
            "epoch:  173 loss:  0.3240498900413513\n",
            "epoch:  174 loss:  0.3236362040042877\n",
            "epoch:  175 loss:  0.323227196931839\n",
            "epoch:  176 loss:  0.32282254099845886\n",
            "epoch:  177 loss:  0.3224222660064697\n",
            "epoch:  178 loss:  0.32202640175819397\n",
            "epoch:  179 loss:  0.32163482904434204\n",
            "epoch:  180 loss:  0.321247398853302\n",
            "epoch:  181 loss:  0.320864200592041\n",
            "epoch:  182 loss:  0.32048505544662476\n",
            "epoch:  183 loss:  0.32010990381240845\n",
            "epoch:  184 loss:  0.3197387754917145\n",
            "epoch:  185 loss:  0.3193714916706085\n",
            "epoch:  186 loss:  0.31900811195373535\n",
            "epoch:  187 loss:  0.3186485469341278\n",
            "epoch:  188 loss:  0.3182927370071411\n",
            "epoch:  189 loss:  0.3179405927658081\n",
            "epoch:  190 loss:  0.3175921142101288\n",
            "epoch:  191 loss:  0.317247211933136\n",
            "epoch:  192 loss:  0.31690582633018494\n",
            "epoch:  193 loss:  0.316567987203598\n",
            "epoch:  194 loss:  0.3162335157394409\n",
            "epoch:  195 loss:  0.3159025013446808\n",
            "epoch:  196 loss:  0.3155747652053833\n",
            "epoch:  197 loss:  0.3152503967285156\n",
            "epoch:  198 loss:  0.3149292767047882\n",
            "epoch:  199 loss:  0.31461137533187866\n",
            "epoch:  200 loss:  0.3142966032028198\n",
            "epoch:  201 loss:  0.3139849901199341\n",
            "epoch:  202 loss:  0.3136764168739319\n",
            "epoch:  203 loss:  0.3133709132671356\n",
            "epoch:  204 loss:  0.3130684196949005\n",
            "epoch:  205 loss:  0.3127689063549042\n",
            "epoch:  206 loss:  0.31247225403785706\n",
            "epoch:  207 loss:  0.31217849254608154\n",
            "epoch:  208 loss:  0.31188762187957764\n",
            "epoch:  209 loss:  0.3115994930267334\n",
            "epoch:  210 loss:  0.3113141655921936\n",
            "epoch:  211 loss:  0.3110315799713135\n",
            "epoch:  212 loss:  0.310751736164093\n",
            "epoch:  213 loss:  0.3104745149612427\n",
            "epoch:  214 loss:  0.31019991636276245\n",
            "epoch:  215 loss:  0.30992791056632996\n",
            "epoch:  216 loss:  0.3096584379673004\n",
            "epoch:  217 loss:  0.3093915581703186\n",
            "epoch:  218 loss:  0.30912715196609497\n",
            "epoch:  219 loss:  0.3088652193546295\n",
            "epoch:  220 loss:  0.3086056709289551\n",
            "epoch:  221 loss:  0.3083485960960388\n",
            "epoch:  222 loss:  0.3080939054489136\n",
            "epoch:  223 loss:  0.3078414499759674\n",
            "epoch:  224 loss:  0.30759143829345703\n",
            "epoch:  225 loss:  0.30734363198280334\n",
            "epoch:  226 loss:  0.3070981204509735\n",
            "epoch:  227 loss:  0.30685481429100037\n",
            "epoch:  228 loss:  0.3066137135028839\n",
            "epoch:  229 loss:  0.30637478828430176\n",
            "epoch:  230 loss:  0.3061380684375763\n",
            "epoch:  231 loss:  0.3059034049510956\n",
            "epoch:  232 loss:  0.3056708872318268\n",
            "epoch:  233 loss:  0.30544039607048035\n",
            "epoch:  234 loss:  0.30521199107170105\n",
            "epoch:  235 loss:  0.3049856126308441\n",
            "epoch:  236 loss:  0.30476126074790955\n",
            "epoch:  237 loss:  0.3045387864112854\n",
            "epoch:  238 loss:  0.304318368434906\n",
            "epoch:  239 loss:  0.30409982800483704\n",
            "epoch:  240 loss:  0.30388322472572327\n",
            "epoch:  241 loss:  0.30366843938827515\n",
            "epoch:  242 loss:  0.30345556139945984\n",
            "epoch:  243 loss:  0.30324453115463257\n",
            "epoch:  244 loss:  0.30303528904914856\n",
            "epoch:  245 loss:  0.3028278946876526\n",
            "epoch:  246 loss:  0.3026222586631775\n",
            "epoch:  247 loss:  0.30241838097572327\n",
            "epoch:  248 loss:  0.30221620202064514\n",
            "epoch:  249 loss:  0.3020158112049103\n",
            "epoch:  250 loss:  0.3018170893192291\n",
            "epoch:  251 loss:  0.3016200065612793\n",
            "epoch:  252 loss:  0.30142462253570557\n",
            "epoch:  253 loss:  0.30123087763786316\n",
            "epoch:  254 loss:  0.3010387122631073\n",
            "epoch:  255 loss:  0.30084824562072754\n",
            "epoch:  256 loss:  0.30065926909446716\n",
            "epoch:  257 loss:  0.3004719316959381\n",
            "epoch:  258 loss:  0.30028611421585083\n",
            "epoch:  259 loss:  0.3001018464565277\n",
            "epoch:  260 loss:  0.29991909861564636\n",
            "epoch:  261 loss:  0.299737811088562\n",
            "epoch:  262 loss:  0.29955804347991943\n",
            "epoch:  263 loss:  0.29937973618507385\n",
            "epoch:  264 loss:  0.29920288920402527\n",
            "epoch:  265 loss:  0.2990274727344513\n",
            "epoch:  266 loss:  0.2988535165786743\n",
            "epoch:  267 loss:  0.2986809015274048\n",
            "epoch:  268 loss:  0.2985096573829651\n",
            "epoch:  269 loss:  0.29833984375\n",
            "epoch:  270 loss:  0.29817143082618713\n",
            "epoch:  271 loss:  0.2980043292045593\n",
            "epoch:  272 loss:  0.2978385090827942\n",
            "epoch:  273 loss:  0.2976740896701813\n",
            "epoch:  274 loss:  0.29751092195510864\n",
            "epoch:  275 loss:  0.2973490357398987\n",
            "epoch:  276 loss:  0.2971884608268738\n",
            "epoch:  277 loss:  0.2970291078090668\n",
            "epoch:  278 loss:  0.2968710660934448\n",
            "epoch:  279 loss:  0.2967142164707184\n",
            "epoch:  280 loss:  0.2965586185455322\n",
            "epoch:  281 loss:  0.29640424251556396\n",
            "epoch:  282 loss:  0.29625099897384644\n",
            "epoch:  283 loss:  0.2960990071296692\n",
            "epoch:  284 loss:  0.29594817757606506\n",
            "epoch:  285 loss:  0.29579851031303406\n",
            "epoch:  286 loss:  0.2956499755382538\n",
            "epoch:  287 loss:  0.29550260305404663\n",
            "epoch:  288 loss:  0.2953563332557678\n",
            "epoch:  289 loss:  0.29521122574806213\n",
            "epoch:  290 loss:  0.2950671911239624\n",
            "epoch:  291 loss:  0.294924259185791\n",
            "epoch:  292 loss:  0.294782429933548\n",
            "epoch:  293 loss:  0.2946416437625885\n",
            "epoch:  294 loss:  0.294501930475235\n",
            "epoch:  295 loss:  0.29436326026916504\n",
            "epoch:  296 loss:  0.29422566294670105\n",
            "epoch:  297 loss:  0.29408904910087585\n",
            "epoch:  298 loss:  0.29395347833633423\n",
            "epoch:  299 loss:  0.29381895065307617\n"
          ]
        }
      ],
      "source": [
        "# instantitate optimizer \n",
        "criterion = nn.BCELoss()  # = nn.CrossEntropyLoss() # for LR with more than 2 classes\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.02, momentum=0.9) #weight_decay=1e-5 -> L2 regularizer\n",
        "\n",
        "# training the model \n",
        "epochs = 300\n",
        "losses = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  y_pred = model.forward(x_train)\n",
        "\n",
        "  # calculate loss \n",
        "  loss = criterion(y_pred, y_train)\n",
        "\n",
        "  # L2 regularizer\n",
        "  l_lambda = 0.01\n",
        "  l_reg = torch.tensor(0.)\n",
        "  for param in model.parameters():\n",
        "      l_reg += torch.norm(param)  # for L1 regularizer : torch.norm(param, 1) \n",
        "      \n",
        "  loss += l_lambda*l_reg\n",
        "\n",
        "  print(\"epoch: \", i, \"loss: \", loss.item())\n",
        "  losses.append(loss.item())\n",
        "\n",
        "  optimizer.zero_grad() # clear gradients wrt parameters\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "rYkUBuB2lfiU",
        "outputId": "3facb4bd-4069-4e9f-a28b-45e3d5d810de"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# log loss\n",
        "plt.plot(range(epochs), losses)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.grid()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80NQ8m48n8fM"
      },
      "source": [
        "# model evalation with new datasets the model has never seen before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReUhXQhwFygw",
        "outputId": "b1cdbfe1-4802-4a05-e135-c2b4984eb491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 2])\n",
            "torch.Size([100, 1])\n"
          ]
        }
      ],
      "source": [
        "X_test = df_test[['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9']].replace({'?':0})\n",
        "Y_test = df_test['class'].replace({2:0, 4:1})\n",
        "# class 2 for benign, 4 for malignant -> 0 for bengn, 1 for malignant\n",
        "\n",
        "x_test = torch.Tensor(np.array([X_test['x1'], X_test['x2']]).astype(np.uint8)).t()  # str to unit, [3, 500] ->  [500, 3]\n",
        "print(x_test.shape)\n",
        "# class 2 for benign, 4 for malignant -> 0 for bengn, 1 for malignant\n",
        "y_test = torch.Tensor(Y_test).unsqueeze(1) # [500] -> [500, 1]\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZcMsmzQHERY",
        "outputId": "8cca1be0-ea3e-4cfd-9dd8-f0cedbee7dd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predcition accuracy_train= 94.32387312186978%\n",
            "Predcition accuracy_test= 98.0%\n"
          ]
        }
      ],
      "source": [
        "#model test w/ all test datasets\n",
        "no_correct = 0\n",
        "for i in range(len(x_train)):\n",
        "  if model.predict(x_train[i]) == y_train[i]:\n",
        "    no_correct += 1\n",
        "\n",
        "accuracy = no_correct/len(x_train)*100\n",
        "print(\"Predcition accuracy_train= {}%\".format(accuracy))\n",
        "\n",
        "no_correct_test=0\n",
        "for i in range(len(x_test)):\n",
        "  if model.predict(x_test[i]) == y_test[i]:\n",
        "    no_correct_test += 1\n",
        "\n",
        "accuracy = no_correct_test/len(x_test)*100\n",
        "\n",
        "print(\"Predcition accuracy_test= {}%\".format(accuracy))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "5b86203fe7d3fdf93e57eb98f3c0d6ef52b3304ead46c0bb19a7d2c13a59c9f0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}